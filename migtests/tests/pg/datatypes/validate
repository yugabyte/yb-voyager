#!/usr/bin/env python3

import common
import os
import yb
import collections

def main():
	test_type_flags = common.valparser()
	
	migration_completed_checks_yb()

	if test_type_flags['ff_enabled'] == 'true':
		migration_completed_checks_ff()
	
	if test_type_flags['fb_enabled'] == 'true':
		migration_completed_checks_fb()

#=============================================================================

EXPECTED_ROW_COUNT = {
 	'num_types': 3,   
	'datatypes1': 3,  
	'datetime_type': 3, 
	'datatypes2': 3,
	'datetime_type2': 2, 
	'null_and_default' :2,
	'decimal_types': 3,
	'hstore_example': 26,
	'tsvector_table': 3,
	'enum_array_table': 3,
}

EXPECTED_SUM_OF_COLUMN = {
	'num_types': {
		'v1': '32621',
		'v2': '-3380617',
		'v3': '564312385451',
		'v4': '993.999',
		'v5': ['9992334.5429','9992334.54290'],
		'v6': '-$12,000,369.60'
	},
	'decimal_types': {
		'n1':'1865936917203721067473070692042057616523559824435284801786158802063081501757370781516738843414444000.095730002',
		'n2':'167981693608097436.14'
	},
}

EXPECTED_ENUM_VALUES = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']
EXPECTED_BYTE_TYPE_VALUES = ['3031303130', '2d61626364', '34343538']

#Due to the large sized source database requirements all tables will come up as colocated for now
EXPECTED_COLOCATION_OF_TABLES = {
	'num_types': 't',   
	'datatypes1': 't',  
	'datetime_type': 't', 
	'datatypes2': 't',
	'datetime_type2': 't', 
	'null_and_default' : 't',
	'decimal_types': 't',
}

def migration_completed_checks_yb():
	print("Running tests on YB")
	yb.run_checks(migration_completed_checks)
	yb.run_checks(YB_specific_checks)

def migration_completed_checks_ff():
	print("Running tests on PG source replica")
	yb.run_checks(migration_completed_checks, db_type="source_replica")

def migration_completed_checks_fb():
	print("Running tests on PG source")
	yb.run_checks(migration_completed_checks, db_type="source")

def migration_completed_checks(tgt):
	table_list = tgt.get_table_names("public")
	print("table_list:", table_list)
	assert len(table_list) == 10

	got_row_count = tgt.row_count_of_all_tables("public")
	for table_name, row_count in EXPECTED_ROW_COUNT.items():
		print(f"table_name: {table_name}, row_count: {got_row_count[table_name]}")
		assert row_count == got_row_count[table_name]

	for table_name, column_names_with_sum in EXPECTED_SUM_OF_COLUMN.items():
		print(f"table_name: {table_name} ---- ")
		for column, sum in column_names_with_sum.items():
			col_sum = tgt.get_sum_of_column_of_table(table_name, column, "public")
			# YB returns .5429 and PG returns .54290. Thus this fails during string comparison
			# TODO Add proper handling for the case
			if column == 'v5' and table_name == 'num_types':
				expected_values = column_names_with_sum[column]
				assert str(col_sum) in expected_values
			else:
				assert str(col_sum) == sum
			print(f"column_name: {column}, sum: {col_sum}")

	distinct_values_enum_types = tgt.get_distinct_values_of_column_of_table("datatypes1", "enum_type", "public")
	print(f"distinct_enum_values:")
	for distinct_value in distinct_values_enum_types:
		print(f"{distinct_value}")
		assert distinct_value.lower() in EXPECTED_ENUM_VALUES

	distinct_values_bool_types = tgt.get_distinct_values_of_column_of_table("datatypes1", "bool_type", "public")
	print(f"distinct_bool_values:")
	for distinct_value in distinct_values_bool_types:
		print(f"{distinct_value}")
		assert distinct_value == 0 or distinct_value == 1

	print(f"distinct_bytea_values:")
	tgt.assert_distinct_values_of_col("datatypes1", "byte_type", "public", 
		transform_func=lambda x: x.hex(), expected_distinct_values=EXPECTED_BYTE_TYPE_VALUES)

	print(f"distinct_json_values:")
	tgt.assert_all_values_of_col("datatypes2", "v1", "public", 
		transform_func=str, expected_values=["{'key1': 'value1', 'key2': 'value2'}", "['a', 'b', 'c', 1, 2, 3]", None])

	print(f"distinct_bit10_values:")
	tgt.assert_distinct_values_of_col("datatypes2", "v2", "public", 
		transform_func=str, expected_distinct_values=['1001100101','0001010101','1001000101'])
	
	print(f"distinct_bit_varying_values:")
	expected_values = ['0001010101','0001010','00101010101010101010101010001010100101010101010101000']
	print(f"expected_values: {expected_values}")
	
	tgt.assert_distinct_values_of_col("datatypes2", "v5", "public", 
		None, expected_distinct_values=expected_values)

	print(f"distinct_int[]_values:")
	tgt.assert_distinct_values_of_col("datatypes2", "v3", "public", 
		expected_distinct_values=[[20000, 14600, 23500, 13250], None])

	print(f"distinct_text[]_values:")
	expected_text_mda_values = [[['â€œFDâ€'], ['act']], [['â€œFDâ€', 'â€œMFâ€'], ['â€œFDâ€', 'â€œPropertyâ€']], [['â€œFDâ€', 'â€œMFâ€'], ['act', 'two']]]
	tgt.assert_distinct_values_of_col("datatypes2", "v4", "public", 
		expected_distinct_values=expected_text_mda_values)

	print(f"distinct_ts_values:")
	tgt.assert_distinct_values_of_col("datetime_type2", "v1", "public", 
		transform_func=str, expected_distinct_values=['2022-11-01 15:55:58.091241', '2022-11-01 15:58:02'])
	
	print("null_and_default:")
	tgt.assert_all_values_of_col("null_and_default", "val", "public", expected_values=["testdefault", None])
	tgt.assert_all_values_of_col("null_and_default", "i", "public", expected_values=[10, None])
	tgt.assert_all_values_of_col("null_and_default", "b", "public", expected_values=[False, None])

	print("hstore_example:")
	expected_hstore_values = [
    '"key1"=>"value1", "key2"=>"value2"',
    '"a\\"b"=>"d\\"a"',
    None,
    '',
    '"key1"=>"value1", "key2"=>"value2"',
    '"key7"=>"value7", "key8"=>"123", "key9"=>"true"',
    '"weight"=>"11.2 ounces", "ISBN-13"=>"978-1449370000", "language"=>"English", "paperback"=>"243", "publisher"=>"postgresqltutorial.com"',
    '"f1"=>"1", "f2"=>"{\\"key1=value1, key2=value2\\"}"',
    '"json_field"=>"{\\"key1=value1, key2={\\"key1=value1, key2=value2\\"}\\"}"',
    '"{\\"key1=value1, key2=value2\\"}"=>"{\\"key1=value1, key2={\\"key1=value1, key2=value2\\"}\\"}"',
    '""=>"emptykey"',
    '"emptyvalue"=>""',
    '"longkey"=>"{}"'.format('x'*10000),
    '"ÐºÐ»ÑŽÑ‡"=>"Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"',
    '"emoji_ðŸ˜€"=>"ðŸ˜ŽðŸ”¥"',
    '"cafÃ©"=>"naÃ¯ve"',
    '"select"=>"statement"',
    '"dup"=>"first"',
    '"key with spaces"=>"value with spaces"',
    '" space_key "=>" space_value "',
    '"key\\"quote"=>"value\\"quote"',
    '"key\'single"=>"value\'single"',
    '"{\\"json_like_key\\":1}"=>"{\\"json_like_value\\":2}"',
	'"\\"{key1:value1,key2:value2}\\""=>"{\\"key1=value1, key2={\\"key1=value1, key2=value2\\"}\\"}"',
	'"\\"{\\"\\"key1\\"\\":\\"\\"value1\\"\\",\\"\\"key2\\"\\":\\"\\"value2\\"\\"}\\""=>"{\\"key1=value1, key2={\\"key1=value1, key2=value2\\"}\\"}"',
	'"key=,=>"=>"value\\\\n\\\\t"'

	]

	tgt.assert_distinct_values_of_col("hstore_example", "data", "public", expected_distinct_values=expected_hstore_values)

	print("tsvector_table:")
	expected_tsvector_titles = ['PostgreSQL Tutorial', 'Advanced SQL', 'Data Migration']
	tgt.assert_distinct_values_of_col("tsvector_table", "title", "public", expected_distinct_values=expected_tsvector_titles)

	print("enum_array_table:")
	# Expected enum arrays as actual Python lists (same pattern as other array tests)
	expected_enum_arrays = [['mon', 'wed', 'fri'], ['tue', 'thu'], ['sat', 'sun']]
	tgt.assert_distinct_values_of_col("enum_array_table", "week_days", "public", 
		expected_distinct_values=expected_enum_arrays)


def YB_specific_checks(tgt):
	yb.verify_colocation(tgt, "postgresql")

if __name__ == "__main__":
	main()
