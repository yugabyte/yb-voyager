### Note: This is a template configuration file for YB Voyager live migration.

# ---------------------------------------------------------
# Global configuration
# ---------------------------------------------------------

### *********** Basic Configuration ************
### Export directory is the workspace used to keep the exported schema, data, state, and logs
### Required
export-dir: <export-dir-path>     

### Log level for yb-voyager 
### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
### Default - info
log-level: info                    

### *********** Control Plane Configuration ************
### To see the Voyager migration workflow details in the UI, set the following parameters.

### Control plane type refers to the deployment type of YugabyteDB
### Accepted value - (yugabyted)
### Optional
control-plane-type: yugabyted  

### YSQL connection string
### Provide the standard PostgreSQL connection parameters, including user name, host name, and port. For example, postgresql://yugabyte:yugabyte@127.0.0.1:5433
### Note: Don't include the dbname parameter in the connection string; the default yugabyte database is used to store the meta information for showing the migration in the yugabyted UI.
### Required if control-plane-type is set to yugabyted
yugabyted-db-conn-string: postgresql://yugabyte:yugabyte@127.0.0.1:5433                            

# ---------------------------------------------------------
# Source Database Configuration
# ---------------------------------------------------------

source:

  ### Source database type: (oracle, postgresql)
  db-type: postgresql    

  ### Source database server host. 
  ### Default - localhost                             
  db-host: localhost 

  ### Source database server port number. 
  ### Default - Oracle(1521), PostgreSQL(5432)                                     
  db-port: 5432    

  ### Source database name to be migrated to YugabyteDB                                       
  db-name: test_db  

  ### Source schema name to export 
  ### Note - This is valid for only Oracle and PostgreSQL source databases.
  ### Note - In case of PostgreSQL, it can be a single or comma separated list of schemas: "schema1,schema2,schema3"                                        
  db-schema: public   

  ### Connect to source database as the specified user                                     
  db-user: test_user   

  ### Source password to connect as the specified user.    
  ### Alternatively, you can also specify the password by setting the environment variable SOURCE_DB_PASSWORD. 
  ### If you don't provide a password via the config, yb-voyager will prompt you at runtime for a password. 
  ### If the password contains special characters that are interpreted by the shell (for example, # and $), enclose the password in single quotes.                               
  db-password: test_password                               

### *********** Source SSL Configuration ************  

  ### Path of the file containing source SSL Certificate         
  # ssl-cert: <ssl-cert-path>  

  ### Specify the source SSL mode out of: (disable, allow, prefer, require, verify-ca, verify-full) 
  ### Oracle does not use explicit sslmode parameters. 
  ### Default - prefer.                          
  # ssl-mode: prefer    

  ### Path of the file containing source SSL Key
  # ssl-key: <ssl-key-path>      

  ### Path of the file containing source SSL Root Certificate
  # ssl-root-cert: <ssl-root-cert-path> 

  ### Path of the file containing source SSL Root Certificate Revocation List (CRL)                  
  # ssl-crl: <ssl-crl-path>    

### *********** Oracle Specific Configuration ************

  ### [For Oracle Only] Oracle System Identifier (SID) that you wish to use while exporting data from Oracle instances
  # oracle-db-sid: <oracle-db-sid>                        

  ### [For Oracle Only] Path to set $ORACLE_HOME environment variable. tnsnames.ora is found in $ORACLE_HOME/network/admin
  # oracle-home: <oracle-home-path>  

  ### [For Oracle Only] Name of TNS Alias you wish to use to connect to Oracle instance. Refer to documentation to learn more about configuring tnsnames.ora and aliases                    
  # oracle-tns-alias: <oracle-tns-alias>    

  ### [For Oracle Only] Oracle System Identifier (SID) of the Container Database that you wish to use while exporting data from Oracle instances.
  # oracle-cdb-sid: <oracle-cdb-sid>

  ### [For Oracle Only] Oracle Container Database Name in case you are using a multitenant container database.
  # oracle-cdb-name: <oracle-cdb-name>

  ### [For Oracle Only] Name of TNS Alias you wish to use to connect to Oracle Container Database in case you are using a multitenant container database. Refer to documentation to learn more about configuring tnsnames.ora and aliases.
  # oracle-cdb-tns-alias: <oracle-cdb-tns-alias>


# ---------------------------------------------------------
# Target Database Configuration
# ---------------------------------------------------------

target:    

  ### Host on which the YugabyteDB server is running. 
  ### Default - 127.0.0.1                          
  db-host: 127.0.0.1      

  ### Port on which the YugabyteDB YSQL API is running. 
  ### Default - 5433                                   
  db-port: 5433  

  ### Name of the database on the target YugabyteDB server on which import needs to be done                                    
  db-name: yugabyte 

  ### Target schema name in YugabyteDB (Note: works only for source as Oracle, in case of PostgreSQL you can ALTER schema name post import)                                    
  # db-schema: public      

  ### Username with which to connect to the target YugabyteDB server                                    
  db-user: test_user      

  ### Password with which to connect to the target YugabyteDB server.    
  ### Alternatively, you can also specify the password by setting the environment variable TARGET_DB_PASSWORD. 
  ### If you don't provide a password via the config, yb-voyager will prompt you at runtime for a password. 
  ### If the password contains special characters that are interpreted by the shell (for example, # and $), enclose the password in single quotes.                          
  db-password: test_password                             

### *********** Target SSL Configuration ************

  ### Path of the file containing target SSL Certificate
  # ssl-cert: <ssl-cert-path>        

  ### Specify the target SSL mode: (disable, allow, prefer, require, verify-ca, verify-full). 
  ### Default - prefer
  # ssl-mode: prefer           

  ### Path of the file containing target SSL Key                                                            
  # ssl-key: <ssl-key-path>      

  ### Path of the file containing target SSL Root Certificate                         
  # ssl-root-cert: <ssl-root-cert-path>     

  ### Path of the file containing target SSL Root Certificate Revocation List (CRL)              
  # ssl-crl: <ssl-crl-path>                               

# ---------------------------------------------------------
# Assess Migration Configuration 
# ---------------------------------------------------------

### Assess the migration from source (postgresql, oracle) database to YugabyteDB.

### Uncomment the respective parameters when you want to configure additional assess migration options.
assess-migration:

  ### Target YugabyteDB version to assess migration for (in format A.B.C.D). 
  ### Default - latest stable version i.e. 2024.2.3.1
  target-db-version: 2024.2.3.1

  ### Interval (in seconds) at which voyager will gather IOPS metadata from source database for the given schema(s). 
  ### Note: Only valid for PostgreSQL
  ### Default - 120                         
  # iops-capture-interval: 120     

  ### Directory path where assessment metadata like source DB metadata and statistics are stored. 
  ### Optional flag, if not provided, it will be assumed to be present at default path inside the export directory.
  # assessment-metadata-dir: <assessment-metadata-dir>  

  ### Run guardrails checks before the command is run. 
  ### Note - This is only valid for PostgreSQL source database.
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info    

# ----------------------------------------------------------
# Export Schema Configuration
# ----------------------------------------------------------

### Export schema from source database into export-dir as .sql files

### Uncomment the respective parameters when you want to configure additional export schema options.
export-schema: 

  ### Provide comma separated list of objects to export or exclude from export.
  ### Note - You can only provide either object-type-list or exclude-object-type-list, not both.
  ###   Accepted parameters for the object-type-list and exclude-object-type-list are:
  ###   Oracle - TYPE, SEQUENCE, TABLE, PACKAGE, TRIGGER, FUNCTION, PROCEDURE, SYNONYM, VIEW, MVIEW
  ###   PostgreSQL - TYPE, DOMAIN, SEQUENCE, TABLE, FUNCTION, PROCEDURE, AGGREGATE, VIEW, MVIEW, TRIGGER, COMMENT                                                 
  # object-type-list: "TABLE,FUNCTION,VIEW"            
  # exclude-object-type-list: "TRIGGER"   

  ### Enable export of comments associated with database objects 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  comments-on-objects: false                                                

  ### Enable using orafce extension in export schema 
  ### Accepted values (true, false, yes, no, 1, 0) 
  ### Only valid for Oracle source databases
  ### Default - true
  # use-orafce: true  

  ### Disable applying recommendations in the exported schema suggested by the migration assessment report
  ### Accepted values (true, false, yes, no, 1, 0)  
  ### Default - false                                       
  # skip-recommendations: false  

  ### Disable applying performance optimizations in the exported schema
  ### Accepted values (true, false, yes, no, 1, 0)  
  ### Default - true                                       
  # skip-performance-optimizations: true  

  ### Path to the generated assessment report file(JSON format) to be used for applying recommendation to exported schema                       
  # assessment-report-path: <assessment-report-path> 

  ### Run guardrails checks before the command is run. 
  ### Note - This is only valid for PostgreSQL source database.
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info        

# ----------------------------------------------------------
# Analyze Schema Configuration
# ----------------------------------------------------------

### Analyze converted source database schema and generate a report about YB incompatible constructs.

### Uncomment the respective parameters when you want to configure additional analyze schema options.
analyze-schema:

  ### Format in which report can be generated: ('html', 'txt', 'json', 'xml'). 
  ### If not provided, reports will be generated in both 'json' and 'html' formats by default.
  # output-format: txt    

  ### Target YugabyteDB version to analyze schema for (in format A.B.C.D). 
  ### Default - latest stable version i.e. 2024.2.3.1
  target-db-version: 2024.2.3.1

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info                           
                                      
                                  
# ----------------------------------------------------------
# Import Schema Configuration
# ----------------------------------------------------------

### Import schema into the target YugabyteDB database

### Uncomment the respective parameters when you want to configure additional import schema options.
import-schema:
  
  ### Comma separated list of schema object types to include while importing schema
  ### Note - You can provide only one of the arguments object-type-list or exclude-object-type-list at a time.
  ### Accepted parameters -
  ###   Oracle - TYPE, SEQUENCE, TABLE, PARTITION, INDEX, PACKAGE, TRIGGER, FUNCTION, PROCEDURE, MVIEW, SYNONYM
  ###   PostgreSQL - SCHEMA, COLLATION, EXTENSION, TYPE, DOMAIN, SEQUENCE, TABLE, INDEX, FUNCTION, AGGREGATE, PROCEDURE, VIEW, TRIGGER, MVIEW, RULE, COMMENT
  # object-type-list: 'TABLE, MVIEW'                              
  # exclude-object-type-list: 'TRIGGER'

  ### Ignore errors and continue with the import 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  continue-on-error: false   

  ### Ignore errors if object already exists 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  ignore-exist: false                                                               
                                                                                                                                 
  ### Imports the schema objects in the order specified via the object-type-list parameter 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # straight-order: false                                                                                   
  
  ### Enable Orafce extension on target
  ### Note - This is only valid for Oracle source database.
  ### Accepted values (true, false, yes, no, 1, 0) 
  ### Default - true
  # enable-orafce: true  

  ### Run guardrails checks before the command is run. 
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info  

# ----------------------------------------------------------
# Export Data Configuration
# ----------------------------------------------------------

### Export tables' data and changes from source database to export-dir. 

### Uncomment this section and the respective parameters when you want to configure additional export data options.
export-data-from-source:

  ### Export type for migration 
  ### Required   
  ### [DO NOT CHANGE]                                              
  export-type: snapshot-and-changes       

  ### Comma-separated list of the table names to include or exclude while exporting data.
  ### Table names can include glob wildcard characters ? (matches one character) and * (matches zero or more characters) 
  ### In case the table names are case sensitive, double-quote them. For example exclude-table-list: 'orders,"Products",items'
  # table-list: 'table1, table2'                          
  # exclude-table-list: 'table3, table4'  

  ### Path of the file containing comma-separated list of table names to include or exclude while exporting data
  ### Note - Only one of table-list or table-list-file-path can be used at a time.
  ### Similarly, only one of exclude-table-list or exclude-table-list-file-path can be used at a time.
  # table-list-file-path: <table-list-file-path>
  # exclude-table-list-file-path: <exclude-table-list-file-path>                    

  ### Number of Parallel Jobs to extract data from source database.
  ### Default - 4
  parallel-jobs: 4    

  ### Disable progress bar/stats during data export  
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # disable-pb: false  

  ### Run guardrails checks before the command is run. 
  ### Note - This is only valid for PostgreSQL source database.
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info                                              

# ---------------------------------------------------------
# Import Data Configuration
# ---------------------------------------------------------

### Import the data exported from the source database into the target database. 

### Uncomment this section and the respective parameters when you want to configure additional import data options.
import-data-to-target:

  ### Control parallelism of data import
  ### By default, Voyager enables adaptive parallelism which adjusts the number 
  ### of parallel jobs based on the resource usage (CPU, memory) of the target 
  ### YugabyteDB cluster.
  ### The following flags are available to control parallelism:
  ### - enable-adaptive-parallelism: Enables adaptive adjustment of parallel jobs.
  ###   Accepted values: true, false, yes, no, 1, 0 
  ###   Default: true
  ### - adaptive-parallelism-max: Optional upper limit on parallel jobs when
  ###   adaptive parallelism is enabled. If not set, Voyager will use N/2,
  ###   where N is the number of available CPU cores.
  ### - parallel-jobs: If set, overrides adaptive parallelism entirely.
  ###   Voyager will use the given number of parallel jobs.
  ###   Any value < 1 falls back to N/4 or 2×node count if N is not available.
  ###   Note: Do not set this if enable-adaptive-parallelism is true.
  enable-adaptive-parallelism: true
  # adaptive-parallelism-max: <integer>
  # parallel-jobs: <integer>   # Do not set if adaptive parallelism is enabled  

  ### Size of batches in the number of rows generated for ingestion during import.
  ### Default - 20000
  # batch-size: 20000  

  ### Action to take on primary key conflict during data import.
  ### Accepted values:
  ###   ERROR   : fail on any PK conflict (default)
  ###   IGNORE  : skip rows where the primary key already exists and continue importing remaining data
  # on-primary-key-conflict: ERROR

  ### Truncate tables on target YugabyteDB before importing data. 
  ### Only applicable along with --start-clean true
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # truncate-tables: false 

  ### It is NOT recommended to have any form of replication (CDC/xCluster) running on the target YugabyteDB cluster during data import. 
  ### If detected, data import is aborted. Use this flag to turn off the checks and continue importing data. 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # skip-replication-checks: false    

  ### Disable progress bar/stats during data import 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # disable-pb: false         

  ### Use the public IPs of the nodes to distribute --parallel-jobs uniformly for data import
  ### Note - you might need to configure database to have public_ip available by setting server-broadcast-addresses.
  ### Refer - https://docs.yugabyte.com/preview/reference/configuration/yb-tserver/#server-broadcast-addresses 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # use-public-ip: false    

  ### Comma separated list of node's endpoint to use for parallel import of data.
  ### For example - "host1:port1,host2:port2" or "host1,host2"
  ### Note - use-public-ip flag will be ignored if this is used.
  ### Default is to use all the nodes in the cluster
  # target-endpoints: "host1:port1,host2:port2"   

  ### The desired behavior when there is an error while processing and importing rows to target YugabyteDB in the snapshot phase. 
  ### The errors can be while reading from file, transforming rows, or ingesting rows into YugabyteDB.
  ### Accepted values:
  ###   abort   : immediately abort the process. (default)
  ###   stash-and-continue: stash the errored rows to a file and continue with the import
  # error-policy-snapshot: abort

  ### Enable UPSERT mode on target tables. WARNING: Ensure that tables on target YugabyteDB do not have secondary indexes. 
  ### If a table has secondary indexes, setting this flag to true may lead to corruption of the indexes. 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  # enable-upsert: false 

  ### Run guardrails checks before the command is run. 
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info    

# ---------------------------------------------------------
# Archive Changes
# ---------------------------------------------------------

### The archive changes command handles old CDC events that have already been applied to the destination database.
### These events are kept in the local export directory until disk usage exceeds a threshold (default: 70%).
### When the threshold is crossed, the command either archives the applied changes to another directory or deletes them.
### This helps manage disk space usage during live migration.

### Uncomment the respective parameters when you want to configure additional archive changes options.
archive-changes:

  ### Delete the imported changes without archiving them.
  ### Note that: the changes are deleted from the export-dir only after disk utilisation exceeds 70%. 
  ### Accepted values (true, false, yes, no, 0, 1)
  ### Default - false
  delete-changes-without-archiving: false

  ### Path to the directory where the imported change events are to be moved to. 
  ### Note that, the changes are deleted from the export-dir only after the disk utilisation exceeds 70%.
  ### Required if delete-changes-without-archiving is set to false.
  move-to: <path-to-archive-dir>

  ### Disk utilization threshold in percentage
  ### Default - 70
  # fs-utilization-threshold: 70

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info 
  
# ---------------------------------------------------------
# Intitiate cutover to target
# ---------------------------------------------------------

### Initiate cutover to target DB

### Uncomment the respective parameters when you want to configure additional cutover options.
initiate-cutover-to-target:

  ### Prepare for fallback by streaming changes from target DB back to source DB.
  ### Note - This should be set to true only if you are planning for fall-back
  ### [DO NOT CHANGE]
  prepare-for-fall-back: false


# ---------------------------------------------------------
# Finalize Schema Post Data Import Configuration
# ---------------------------------------------------------

### Finalize schema after data import is complete.

### Uncomment the respective parameters when you want to configure additional finalize schema post data import options.
finalize-schema-post-data-import:
  
  ### Ignore errors and continue with the import 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  continue-on-error: false                                    
  
  ### Ignore errors if object already exists 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  ignore-exist: false                                         
  
  ### Refreshes the materialised views on target during post snapshot import phase  
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Default - false
  refresh-mviews: false

  ### Run guardrails checks before the command is run. 
  ### Accepted values - (true, false, yes, no, 1, 0)
  ### Default - true
  # run-guardrails-checks: true  

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info                                        

# ---------------------------------------------------------
# End Migration Configuration
# ---------------------------------------------------------

### End the current migration and cleanup all metadata stored in databases(Target and Source) and export-dir

### Uncomment the respective parameters when you want to configure additional end migration options.
end-migration:
  
  ### Backup migration schema files 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Required
  backup-schema-files: false                                  
  
  ### Backup snapshot data files 
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Required
  backup-data-files: false                                    
  
  ### Save migration assessment report, analyze schema report and data migration reports
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Required
  save-migration-reports: false                               
  
  ### Backup yb-voyager log files for this migration
  ### Accepted values (true, false, yes, no, 1, 0)
  ### Required
  backup-log-files: false                                    
  
  ### Backup directory is where all the backup files of schema, data, logs and reports will be saved
  ### Note: Mandatory if any of the following flags are set to true or yes or 1: --backup-data-files, --backup-log-files, --backup-schema-files, --save-migration-reports.
  # backup-dir: <backup-dir-path> 

  ### Log level for the command
  ### Note: This overrides the global log-level parameter for this command only.
  ### Accepted values - (trace, debug, info, warn, error, fatal, panic) 
  ### Default - info
  # log-level: info                              

# ---------------------------------------------------------
# Config File End
# ---------------------------------------------------------
