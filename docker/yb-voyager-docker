#!/bin/bash

# set -x

argv=( "$@" )

if ! which docker > /dev/null
then
	echo "Could not find docker! Please install docker before proceeeding."
	exit 1
fi

if [[ $OSTYPE == 'darwin'* ]]
then
	platform="--platform=linux/amd64"
fi

exported_vars=""
volume_mappings=""

# Define an array of environment variable names to capture
variables=("BETA_FAST_DATA_EXPORT" 
"SOURCE_DB_PASSWORD" 
"TARGET_DB_PASSWORD" 
"SOURCE_REPLICA_DB_PASSWORD" 
"YB_VOYAGER_SEND_DIAGNOSTICS" 
"YB_MASTER_PORT" 
"YB_TSERVER_PORT" 
"QUEUE_SEGMENT_MAX_BYTES" 
"NUM_EVENT_CHANNELS" 
"EVENT_CHANNEL_SIZE" 
"MAX_EVENTS_PER_BATCH" 
"MAX_INTERVAL_BETWEEN_BATCHES"
"CONTROL_PLANE_TYPE"
"YUGABYTED_DB_CONN_STRING"
"CSV_READER_MAX_BUFFER_SIZE_BYTES"
"LOCAL_CALL_HOME_SERVICE_HOST"
"LOCAL_CALL_HOME_SERVICE_PORT"
"APP_CHANGES_HIGH_THRESHOLD"
"APP_CHANGES_MEDIUM_THRESHOLD"
"SCHEMA_CHANGES_HIGH_THRESHOLD"
"SCHEMA_CHANGES_MEDIUM_THRESHOLD")

volume_dirs=("--export-dir" 
"--backup-dir" 
"--move-to" 
"--source-ssl-cert" 
"--source-ssl-key" 
"--source-ssl-root-cert"
"--table-list-file-path"
"--exclude-table-list-file-path"
"--assessment-metadata-dir"
"--assessment-report-path"
"--bulk-assessment-dir"
"--fleet-config-file")

# Loop through the array and capture the environment variables
for var_name in "${variables[@]}"; do
  var=$(env | grep -E "$var_name")
  if [[ -n "$var" ]]; then
    exported_vars="${exported_vars} -e $var"
  fi
done

flags_to_store=("--source-ssl-cert"
"--source-ssl-key"
"--source-ssl-root-cert"
" --source-ssl-crl"
"--target-ssl-root-cert"
"--target-ssl-crl"
"--target-ssl-cert"
"--target-ssl-key"
"--source-replica-ssl-cert"
"--source-replica-ssl-crl"
"--source-replica-ssl-key"
"--source-replica-ssl-root-cert")

exported_vars="${exported_vars} -e ORACLE_HOME=/usr/lib/oracle/21/client64 -e LD_LIBRARY_PATH=/usr/lib/oracle/21/client64/lib -e PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin:/usr/lib/oracle/21/client64/bin"

# if command is like yb-voyager export data. The command name is export data.
command_name=${argv[0]}-${argv[1]}
# if argv[2] is "from" or "to" then command name is like import data from source or import data to target
if [[ ${argv[2]} == "from" || ${argv[2]} == "to" ]]
then
	command_name=${argv[0]}-${argv[1]}-${argv[2]}-${argv[3]}
fi
command_metadata_file_name="/tmp/docker-metadata-${command_name}.txt"
export_dir=""

map_host_path_inside_container() {
		flag_name=$1
		dir_path=$2
		# If flag_name is "" then we have to extract it from argv
		if [[ $flag_name == "" ]]
		then
			flag_name=${argv[${i}]}
			j=$(( $i + 1))
			argv[${j}]=$(realpath "${argv[${j}]}")
			dir_path=${argv[${j}]}
		fi
        echo "mapping host path ${dir_path} for flag ${flag_name}"
		volume_name="voyager-${flag_name}"
		# handle file paths.  If the path is a file, then the target path should be the directory of the file.
		if [[ -f $dir_path ]]
		then
			dir_path=$(dirname "$dir_path")
		fi
		# If the OS is macOS
		if [[ $OSTYPE == 'darwin'* ]] 
		then
			docker volume rm $volume_name > /dev/null 2>&1
			docker volume create --driver local --opt type=none --opt device="${dir_path}" --opt o=bind $volume_name > /dev/null 2>&1
			volume_mappings="${volume_mappings} -v ${volume_name}:${dir_path}"
		else
			volume_mappings="${volume_mappings} -v ${dir_path}:${dir_path}"
		fi
}

# function to handle the mapping and storage of directory paths
handle_directory_flag() {
    local flag=$1
    local path=$2
    # Map the path to Docker volume
    map_host_path_inside_container "$flag" "$path"
    # Store the flag and path in metadata file if necessary
    if [[ " ${flags_to_store[@]} " =~ " ${flag} " ]]; then
        echo "${flag} ${path}" >> $command_metadata_file_name
    fi
}

# function to handle data directory specifics, including cloud paths
handle_data_dir() {
    local index=$1
    local data_dir=${argv[$(( index + 1 ))]}

    case $data_dir in
        s3://*)
            # Capture AWS-specific variables
            for var in $(env | grep -E '^AWS_'); do
                exported_vars="${exported_vars} -e $var"
            done
            s3_vol="-v ${HOME}/.aws:/root/.aws"
            ;;
        gs://*)
            # map gcp credentials directory
            gcp_vol="-v ${HOME}/.config/gcloud:/root/.config/gcloud"
            ;;
        https://*)
            # map azure credentials directory
            azure_vol="-v ${HOME}/.azure:/root/.azure"
            ;;
        *)
            # If the data-dir is not an S3 bucket
			data_dir=$(realpath "$data_dir")
            map_host_path_inside_container "data-dir" "$data_dir"
            ;;
    esac
    return 1  # Skip the next parameter
}

process_flag() {
    local flag=$1
    local index=$2

    case "$flag" in
        "-e" | "--export-dir")
            export_dir=${argv[$(( index + 1 ))]}
            handle_directory_flag "--export-dir" "$export_dir"
            return 1  # Skip the next parameter
            ;;
        "--data-dir")
            handle_data_dir $index
            return $?  # Return the increment defined in handle_data_dir
            ;;
        "--oracle-tns-alias" | "--fleet-config-file")
            if [[ "$flag" == "--fleet-config-file" ]]; then
                local dir_path=${argv[$(( index + 1 ))]}
                handle_directory_flag "$flag" "$dir_path"
            fi
            local tns_admin=${TNS_ADMIN:-"${ORACLE_HOME}/network/admin"}
            local wallet_dir=$(sed -n 's|(DIRECTORY\s*=\s*"\([^"]*\)")|\1|p' "${tns_admin}/sqlnet.ora" | xargs)
            tns_admin=$(realpath "$tns_admin")
            wallet_dir=$(realpath "$wallet_dir")
            handle_directory_flag "oracle-tns-alias" "$tns_admin"
            handle_directory_flag "oracle-wallet-dir" "$wallet_dir"
            exported_vars="${exported_vars} -e TNS_ADMIN=$tns_admin"
            return 1
            ;;
        *)
            if [[ " ${volume_dirs[@]} " =~ " ${flag} " ]]; then
                local dir_path=${argv[$(( index + 1 ))]}
                handle_directory_flag "$flag" "$dir_path"
                return 1  # Skip the next parameter
            fi
            ;;
    esac
    return 0
}


if [ -f "$command_metadata_file_name" ]
then
	rm $command_metadata_file_name
fi

# Main loop for processing command-line arguments
i=0
while [ $i -lt $# ]; do
    echo "Current flag: ${argv[$i]}"
    process_flag "${argv[$i]}" $i
    increment=$?
    i=$(( i + increment + 1 ))
done


# If the metadata file exists then move it to the export_dir and overwrite any existing file.
if [ -f "$command_metadata_file_name" -a -n "$export_dir" ]
then
	# Check if the meta directory exists in the export_dir. If not, create it.
	if [ ! -d "$export_dir/metainfo" ]
	then
		mkdir -p $export_dir/metainfo
	fi
	mv $command_metadata_file_name $export_dir/metainfo
fi

if [ -t 1 ] 
then 
	tty="-it"
fi

# If the command is end migration or export data from target or import data to source or get data-migration-report then map the paths saved in the metadata files to the container.
if [[ ${command_name} == "end-migration" || ${command_name} == "export-data-from-target" || ${command_name} == "import-data-to-source" || ${command_name} == "get-data-migration-report" ]]
then
    # There are multiple files saved in export dir which start with docker-metadata-*. Read each file and map the paths to the container.
	for file in $(ls $export_dir/metainfo/docker-metadata-*)
	do
		while read line
		do
			flag_name=$(echo $line | awk '{print $1}')
			dir_path=$(echo $line | awk '{print $2}')
			map_host_path_inside_container $flag_name $dir_path
		done < $file
	done
fi

dockerCmd="docker run ${exported_vars} ${tty} ${gcp_vol} ${s3_vol} ${azure_vol} ${volume_mappings} --pid=host --network=host --rm --privileged ${platform} yugabytedb/yb-voyager yb-voyager ${argv[*]}"

echo $dockerCmd

$dockerCmd
